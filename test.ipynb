{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count generated trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "651\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "data_path = 'data/json_2.1.0_Recep:original-bert'\n",
    "feat_path = 'data/json_feat_2.1.0'\n",
    "for split in ['valid_seen', 'valid_unseen']:\n",
    "    cnt = 0\n",
    "    for ep in os.listdir(os.path.join(data_path, split)):\n",
    "        if os.path.isfile(os.path.join(data_path, split, ep)):\n",
    "            continue\n",
    "        for trial in os.listdir(os.path.join(data_path, split, ep)):\n",
    "            for file in os.listdir(os.path.join(feat_path, ep, trial, 'pp')):\n",
    "                if file.endswith('.json'):\n",
    "                    cnt += 1\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare generation fail cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "fail = {}\n",
    "with open('gen/exp/0.3/fail-valid_seen.json') as f:\n",
    "    recep = json.load(f)\n",
    "with open('gen/exp/0.3/fail-valid_seen-pddlMatched.json') as f:\n",
    "    recep_matched = json.load(f)\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "for key in recep_matched:\n",
    "    if key not in recep:\n",
    "        fail.update({key: recep_matched[key]})\n",
    "    \n",
    "total = 0  \n",
    "cnt = 0\n",
    "for trial, error in fail.items():\n",
    "    total += 1\n",
    "    if 'Empty plan' in error['error']:\n",
    "        cnt += 1\n",
    "print(total)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare fail cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이건 시뮬레이터로 실행시켜서 봐야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare generated pddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def process_task(raw_tasks):\n",
    "    tasks = []\n",
    "    for t in raw_tasks:\n",
    "        if '\\n' in t:\n",
    "            tasks.extend([_t.replace('\\b', '').strip() for _t in t.split('\\n') if _t != ''])\n",
    "        else:\n",
    "            tasks.append(t.replace('\\b', '').strip())\n",
    "    return tasks\n",
    "\n",
    "with open('gen/scripts/roberta-sentence_match.json', 'r') as f:\n",
    "    sentence_match = json.load(f)\n",
    "with open('gen/scripts/pddl_match.json') as f:\n",
    "    prediction_pddl_match = json.load(f)\n",
    "    \n",
    "log = ''\n",
    "data_path = 'data/json_2.1.0'\n",
    "for split in ['valid_seen', 'valid_unseen']:\n",
    "    for ep in os.listdir(os.path.join(data_path, split)):\n",
    "        if os.path.isfile(os.path.join(data_path, split, ep)):\n",
    "            continue\n",
    "        for trial in os.listdir(os.path.join(data_path, split, ep)):\n",
    "            with open(os.path.join(data_path, split, ep, trial, 'traj_data.json')) as f:\n",
    "                traj_data = json.load(f)\n",
    "            pddl = traj_data['pddl_params']\n",
    "            tasks = process_task([ann['task_desc'] for ann in traj_data['turk_annotations']['anns']])\n",
    "            predicted_pddl = [prediction_pddl_match[t] for t in tasks]\n",
    "            \n",
    "            for i, task in enumerate(tasks):\n",
    "                if pddl == predicted_pddl[i]:\n",
    "                    continue\n",
    "                idx = sentence_match['pred'].index(task)\n",
    "                log += os.path.join(ep, trial)+'\\n'\n",
    "                log += '%20s: %s\\n' % ('valid', task)\n",
    "                log += '%20s: %s\\n' % ('matched train task', sentence_match['gt'][idx])\n",
    "                log += '-'*50 + '\\n'\n",
    "                log += '%15s %15s %15s\\n'%('params', 'predicted pddl', 'gt pddl')\n",
    "                for p, v in pddl.items():\n",
    "                    log += '%15s|%15s|%15s\\n'%(p, predicted_pddl[i][p], v)\n",
    "                log += '-'*50 + '\\n\\n\\n'\n",
    "with open('log-roberta.txt', 'w') as f:\n",
    "    f.write(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make input.txt for eval trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = []\n",
    "for ep in os.listdir(os.path.join('data/json_2.1.0_Recep:original-gpt2/valid_seen')):\n",
    "    if os.path.isfile(os.path.join('data/json_2.1.0_Recep:original-gpt2/valid_seen', ep)):\n",
    "        continue\n",
    "    for trial in os.listdir(os.path.join('data/json_2.1.0_Recep:original-gpt2/valid_seen', ep)):\n",
    "        input.append(os.path.join('.', ep, trial))\n",
    "        \n",
    "with open(os.path.join('data/json_2.1.0_Recep:original-gpt2/valid_seen', 'input.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_valid_seen-recep:0.3.txt', 'r') as f:\n",
    "    l = f.readlines()\n",
    "l = list(set(l))\n",
    "with open('found_valid_seen-recep:0.3.txt', 'w') as f:\n",
    "    f.write(''.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('alfred')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "facb029533ca1e4106d94c670820873af2e18ea510b2a3b0c0237f94a22c90ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
